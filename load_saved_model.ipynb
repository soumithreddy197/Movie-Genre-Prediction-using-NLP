{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace, split\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import HashingTF,IDF\n",
    "from pyspark.sql.functions import *\n",
    "import re\n",
    "\n",
    " \n",
    "spark = (SparkSession.builder\n",
    "                  .appName('Toxic Comment Classification')\n",
    "                  .enableHiveSupport()\n",
    "                  .config(\"spark.executor.memory\", \"4G\")\n",
    "                  .config(\"spark.driver.memory\",\"18G\")\n",
    "                  .config(\"spark.executor.cores\",\"7\")\n",
    "                  .config(\"spark.python.worker.memory\",\"4G\")\n",
    "                  .config(\"spark.driver.maxResultSize\",\"0\")\n",
    "                  .config(\"spark.sql.crossJoin.enabled\", \"true\")\n",
    "                  .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\n",
    "                  .config(\"spark.default.parallelism\",\"2\")\n",
    "                  .config(\"spark.speculation\",\"false\")\n",
    "                  .getOrCreate())\n",
    "\n",
    "#spark.conf.set(\"spark.sql.shuffle.partitions\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = pd.read_csv('/home/cse587/train.csv')\n",
    "test_df = pd.read_csv('/home/cse587/test.csv')\n",
    "genre_all=['Drama', 'Comedy','Romance Film','Thriller','Action','World cinema','Crime Fiction','Horror','Black-and-white','Indie','Action/Adventure','Adventure','Family Film','Short Film','Romantic drama','Animation','Musical','Science Fiction','Mystery','Romantic comedy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySchema = StructType([ StructField(\"movie_id\", LongType())\\\n",
    "                       ,StructField(\"movie_name\", StringType())\\\n",
    "                       ,StructField(\"plot\", StringType())\\\n",
    "                       ,StructField(\"genre\", StringType())])\n",
    "testSchema = StructType([ StructField(\"movie_id\", LongType())\\\n",
    "                       ,StructField(\"movie_name\", StringType())\\\n",
    "                       ,StructField(\"plot\", StringType())])\n",
    "\n",
    "df = spark.createDataFrame(pd_df,schema=mySchema)\n",
    "test_df = spark.createDataFrame(test_df,schema=testSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.select('movie_id','movie_name',(lower(regexp_replace('plot', \"[^a-zA-Z\\\\s]\", \"\")).alias('plot')),'genre')\n",
    "tdf_clean = test_df.select('movie_id','movie_name',(lower(regexp_replace('plot', \"[^a-zA-Z\\\\s]\", \"\")).alias('plot')))\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='plot', outputCol='words_token')\n",
    "df_words_token = tokenizer.transform(df_clean).select('movie_id','movie_name','words_token','genre')\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='plot', outputCol='words_token')\n",
    "tdf_words_token = tokenizer.transform(tdf_clean).select('movie_id','movie_name','words_token')\n",
    "\n",
    "remover = StopWordsRemover(inputCol='words_token', outputCol='plot_clean')\n",
    "df_words_no_stopw = remover.transform(df_words_token).select('movie_id','movie_name','plot_clean','genre' )\n",
    "\n",
    "remover = StopWordsRemover(inputCol='words_token', outputCol='plot_clean')\n",
    "tdf_words_no_stopw = remover.transform(tdf_words_token).select('movie_id','movie_name','plot_clean' )\n",
    " \n",
    "df.unpersist()\n",
    "df_clean.unpersist()\n",
    "df_words_token.unpersist()\n",
    "test_df.unpersist()\n",
    "tdf_clean.unpersist()\n",
    "tdf_words_token.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_string=StringIndexer(inputCol=\"genre\",outputCol=\"label\")\n",
    "lsm=label_string.fit(df_words_no_stopw)\n",
    "tfidf4=lsm.transform(df_words_no_stopw)\n",
    "#tfidf4.printSchema()\n",
    "#tfidf4.show(1,truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(vectorSize = 10, minCount = 1200, inputCol = 'plot_clean', outputCol = 'features')\n",
    "word_df = word2vec.fit(tfidf4)\n",
    "\n",
    "word2vec_df = word_df.transform(tfidf4)\n",
    "word2vec_tdf = word_df.transform(tdf_words_no_stopw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "#nb = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\",numTrees = 7)\n",
    "\n",
    "#model = nb.fit(word2vec_df) \n",
    "#predictions.show()\n",
    "model = RandomForestClassificationModel.load(\"word2vec_trained_model\")\n",
    "\n",
    "predictions = model.transform(word2vec_tdf)\n",
    "\n",
    "word2vec_df.unpersist()\n",
    "\n",
    "word2vec_tdf.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=lsm.labels)\n",
    "pdf=labelConverter.transform(predictions)\n",
    "#pdf.show(10)\n",
    "\n",
    "def col_convert(l):\n",
    "  x=re.sub(\"'\",\"\",l)\n",
    "  x=re.sub(\" \",\"\",x)\n",
    "  li=x[1:len(x)-1].split(\",\")\n",
    "  req_li=[str(0)]*20\n",
    "  for j in range(0,len(genre_all)):\n",
    "    for i in range(0,len(li)): \n",
    "      if(li[i]==genre_all[j]):\n",
    "        req_li[j]=str(1)\n",
    "  t =\" \".join(req_li)\n",
    "  return t\n",
    "\n",
    "udf_col=udf(col_convert,StringType())\n",
    "df13=pdf.select('movie_id','predictedLabel')\n",
    "df13=df13.withColumn(\"col9\",udf_col(df13['predictedLabel']))\n",
    "testdf=df13.select('movie_id','col9')\n",
    "testdf.coalesce(1).write.csv('test_random_word2vec.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
